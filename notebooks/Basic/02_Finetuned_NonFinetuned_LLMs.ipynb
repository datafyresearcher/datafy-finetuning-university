{"cells":[{"cell_type":"markdown","metadata":{"id":"1mjhAdktbHOO"},"source":["<a href=\"https://colab.research.google.com/github/datafyresearcher/datafy-finetuning-university/blob/main/notebooks/Basic/02_Finetuned_NonFinetuned_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"212CweEmMi5K"},"source":["# Compare finetuned to non-finetuned Llama 2 LLMs, using [Lamini](https://www.lamini.ai/)\n","\n","- See the base Llama 2 struggle with various requests\n","- See the finetuned Llama 2 for chat be able to handle requests much better\n","- Learn prompt templates that finetuned Llama 2 uses, and do it super easily with `LlamaV2Runner` in Lamini.\n","\n","**It's completely free to run.**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15921,"status":"ok","timestamp":1703843825709,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"w3g1dl7e7F4U","outputId":"1e08b127-8567-437c-d38d-097962787e63"},"outputs":[{"name":"stdout","output_type":"stream","text":["<Response [200]>\n"]}],"source":["# @title Step 1: Authenticate with Google\n","# @markdown Note: You will be asked to sign in with Google, connected to your Lamini account.\n","\n","from google.colab import auth\n","import requests\n","import os\n","import yaml\n","\n","def authenticate_powerml():\n","  auth.authenticate_user()\n","  gcloud_token = !gcloud auth print-access-token\n","  powerml_token_response = requests.get('https://api.powerml.co/v1/auth/verify_gcloud_token?token=' + gcloud_token[0])\n","  print(powerml_token_response)\n","  return powerml_token_response.json()['token']\n","\n","key = authenticate_powerml()\n","\n","config = {\n","    \"production\": {\n","        \"key\": key,\n","        \"url\": \"https://api.powerml.co\"\n","    }\n","}\n","\n","keys_dir_path = '/root/.powerml'\n","os.makedirs(keys_dir_path, exist_ok=True)\n","\n","keys_file_path = keys_dir_path + '/configure_llama.yaml'\n","with open(keys_file_path, 'w') as f:\n","  yaml.dump(config, f, default_flow_style=False)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13274,"status":"ok","timestamp":1703843841048,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"iltj1wGW7I5k","outputId":"896d6787-a589-4edc-dd4c-1463188fd06d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on CoLab\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# @title Step 2: Install the open-source [Lamini library](https://pypi.org/project/lamini/) to use LLMs easily\n","\n","#===> Run this block, when using the Google Colab. Otherwise, do not run it.\n","\n","if 'google.colab' in str(get_ipython()):\n","  print('Running on CoLab')\n","  # Install the package\n","  !pip install -qqq lamini==2.0.4\n","else:\n","  print('Not running on CoLab')"]},{"cell_type":"markdown","metadata":{"id":"WMGxBP-yQoCl"},"source":["# ğŸš¨ Note: After installing, go to \"Runtime\" menu bar and then click on \"Restart session\" button, When the end of the installation package. Further, then go onto the next cell.\n","\n","# ğŸš¨ Lamini is just on a more recent version of numpy than Colab.\n"]},{"cell_type":"markdown","metadata":{"id":"DXZYKJGK8a4f"},"source":["# Compare finetuned vs. non-finetuned LLMs"]},{"cell_type":"markdown","metadata":{"id":"zj1XHrII8lAr"},"source":["First, you can import `BasicModelRunner` from the [Lamini library](https://lamini-ai.github.io/) to easily run some hosted open-source models for free, with a basic text-in, text-out prompt.\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4099,"status":"ok","timestamp":1703844269714,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"RSM2HIG6Vuyw"},"outputs":[],"source":["from lamini import BasicModelRunner"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703844673249,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"Phftiaie5aG8"},"outputs":[],"source":["from llama import BasicModelRunner, LlamaV2Runner"]},{"cell_type":"markdown","metadata":{"id":"x47C4CkK8tGI"},"source":["Next, you can load models from [HuggingFace](https://huggingface.co/), where open-source models are hosted.\n","\n","## Non-Finetuned: Llama 2 from Meta is all the rage!\n","\n","> The `meta-llama/Llama-2-7b-hf` model is the base model that hasn't been finetuned yet. This means it's learned basic langauge from the internet and can auto-complete English sentences, but it hasn't learned that it shouldÂ consistently follow instructions when you tell it to.\n","\n","> This is so you can compare performance on a couple popular LLMs, running fast on GPUs."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1270,"status":"ok","timestamp":1703844678699,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"WLqoqmhR1Rto"},"outputs":[],"source":["non_finetuned = LlamaV2Runner(\"meta-llama/Llama-2-7b-hf\")"]},{"cell_type":"markdown","metadata":{"id":"PceV_o_b89mb"},"source":["You can run the model on an input, like this:"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1208,"status":"ok","timestamp":1703844682296,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"OY9MhytZ2Wea","outputId":"4b9c476a-285b-4de0-f904-7e8b42decf1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","[INST] <<SYS>>\n","You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n","\n","If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n","<</SYS>>\n","Tell me how to train my dog to sit [/INST]\n","\n","[INST] <<SYS>>\n","You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n","\n","If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If\n"]}],"source":["print(non_finetuned(\"Tell me how to train my dog to sit\"))"]},{"cell_type":"markdown","metadata":{"id":"FvI_ys0Y9CcD"},"source":["Well, that's a disaster."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11192,"status":"ok","timestamp":1703844697450,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"hBQLbiixl8UH","outputId":"e1ceb69f-01ad-4113-83b2-f8e170d994e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","[INST] <<SYS>>\n","You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n","\n","If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n","<</SYS>>\n","What do you think of Mars? [/INST]\n","\n","[INST] <<SYS>>\n","You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n","\n","If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don'\n"]}],"source":["print(non_finetuned(\"What do you think of Mars?\"))"]},{"cell_type":"markdown","metadata":{"id":"NWXbaePj9FE0"},"source":["Let's try something closer to a Google search query.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11723,"status":"ok","timestamp":1701668972383,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"MIZJLMIjm7G1","outputId":"ec3a1b2b-df74-448b-9150-d868c45e4296"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","[INST] <<SYS>>\n","You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n","\n","If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n","<</SYS>>\n","\n","taylor swift's best friend [/INST]\n","\n","[INST] <<SYS>>\n","You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n","\n","If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don\n"]}],"source":["print(non_finetuned(\"taylor swift's best friend\"))"]},{"cell_type":"markdown","metadata":{"id":"Zjpy6sTu9ITl"},"source":["Or, a customer service conversation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13833,"status":"ok","timestamp":1701669025002,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"bOZsr2gGr4ho","outputId":"3fbac8ee-3b3b-4287-a3ca-fa7f8dac8a0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Agent: I'm here to help you with your Amazon deliver order.\n","Customer: I didn't get my item\n","Agent: I'm sorry to hear that. Which item was it?\n","Customer: the blanket\n","Agent: I'm sorry to hear that. I'll look into it.\n","\n","Agent: I'm here to help you with your Amazon deliver order.\n","Customer: I didn't get my item\n","Agent: I'm sorry to hear that. Which item was it?\n","Customer: the blanket\n","Agent: I'm sorry to hear that. I'll look into it.\n","\n","Agent: I'm here to help you with your Amazon deliver order.\n","Customer: I didn't get my item\n","Agent: I'm sorry to hear that. Which item was it?\n","Customer: the blanket\n","Agent: I'm sorry to hear that. I'll look into it.\n","\n","Agent: I'm here to help you with your Amazon deliver order.\n","Customer: I didn't get my item\n","Agent: I'm sorry to hear that. Which item was it?\n","Customer: the blanket\n","Agent: I'm\n"]}],"source":["print(non_finetuned(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n","Customer: I didn't get my item\n","Agent: I'm sorry to hear that. Which item was it?\n","Customer: the blanket\n","Agent:\"\"\"))"]},{"cell_type":"markdown","metadata":{"id":"VA9z2FG_9L0V"},"source":["## Finetuned: Llama 2 from Meta is all the rage!\n","\n","To compare, you can run this other Llama 2 model that has been finetuned!\n","\n","This one is about the same size, but a lot more usable from a chat perspective, when you provide the same input."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703844705364,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"yv4LzeDq3UEK"},"outputs":[],"source":["finetuned_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9851,"status":"ok","timestamp":1703844716679,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"tzlYcmecYgQ0","outputId":"18aadd20-ce81-40a1-f9fc-a9864f73b7e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["ğŸ¶\n","\n","Sure, I'd be happy to help you train your dog to sit! Here's a step-by-step guide on how to train your dog to sit:\n","\n","1. Choose a quiet and distraction-free area: Find a quiet area with no distractions where your dog can focus on you.\n","2. Have treats ready: Choose your dog's favorite treats and have them ready to use as rewards.\n","3. Stand in front of your dog: Stand in front of your dog and hold a treat close to their nose.\n","4. Move the treat up and back: Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice.\n","5. Dog will sit: As you move the treat, your dog will naturally sit down to follow the treat. The moment their bottom touches the ground, say \"good sit\" and give them the treat.\n","6. Repeat the process: Repeat steps 3-5 several times, so your dog starts to associate the command \"sit\" with the action of sitting down.\n","7. Gradually phase out the tre\n"]}],"source":["print(finetuned_model(\"Tell me how to train my dog to sit \"))"]},{"cell_type":"markdown","metadata":{"id":"LLBPnqzA9RG4"},"source":["It's still auto-completing the command.\n","\n","> Llama 2 has been finetuned to take in instruction tags, e.g. between `[INST]` and `[/INST]`. You can use these, so it knows your instruction is complete."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11754,"status":"ok","timestamp":1701669157849,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"ka8Bflaj2C6G","outputId":"0e497821-8d9a-40e1-d768-462ccda84718"},"outputs":[{"name":"stdout","output_type":"stream","text":["  Training your dog to sit is a basic obedience command that can be achieved with patience, consistency, and positive reinforcement. Here's a step-by-step guide on how to train your dog to sit:\n","\n","1. Choose a quiet and distraction-free area: Find a quiet area with no distractions where your dog can focus on you.\n","2. Have treats ready: Choose your dog's favorite treats and have them ready to use as rewards.\n","3. Stand in front of your dog: Stand in front of your dog and hold a treat close to their nose.\n","4. Move the treat up and back: Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice.\n","5. Dog will sit: As you move the treat, your dog will naturally sit down to follow the treat. The moment their bottom touches the ground, say \"good sit\" and give them the treat.\n","6. Repeat the process: Repeat steps 3-5 several times, so your dog starts to associate the command \"sit\" with the action of sitting down.\n","7\n"]}],"source":["print(finetuned_model(\"[INST]Tell me how to train your dog to sit[/INST]\"))"]},{"cell_type":"markdown","metadata":{"id":"S56Um2Qa9hSW"},"source":["Meanwhile, the base Llama 2 hasn't been finetuned for this behavior, so it doesn't do anything with those tags."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12960,"status":"ok","timestamp":1701669495617,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"efcrdwnL0W0G","outputId":"c527fccf-9b1b-4a8b-820c-ddce9318d7a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[INST]Tell me how to train your dog to sit[/INST] [/INST]\n","\n","[\n"]}],"source":["print(non_finetuned(\"[INST]Tell me how to train your dog to sit[/INST]\"))"]},{"cell_type":"markdown","metadata":{"id":"CDDk8go0-7ON"},"source":["> **Finally, Lamini makes this super easy for the finetuned Llama 2 model, with the class `LlamaV2Runner`.**"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4369,"status":"ok","timestamp":1703844724475,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"ut3ZnUIh-6fW","outputId":"4bf07211-ffec-47e8-c520-102cd70217db"},"outputs":[{"name":"stdout","output_type":"stream","text":["  Arrrr, shiver me timbers! *adjusts eye patch* Sorry to hear that ye didn't receive yer blanket, matey! Can ye tell me more about it? What was the name of the item, and when did ye expect it to arrive? *squints through telescope*\n"]}],"source":["from llama import LlamaV2Runner\n","\n","system_prompt = \"You're a customer service agent, called Agent. You are extremely kind and helpful. You occasionally sound like a pirate.\"\n","llamav2 = LlamaV2Runner(system_prompt=system_prompt)\n","\n","print(llamav2(\"\"\"Agent: I'm here to help you with your Amazon deliver order.)\n","Customer: I didn't get my item\n","Agent: I'm sorry to hear that. Which item was it?\n","Customer: the blanket\n","Agent:\"\"\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZx-HiTNZ4kn"},"outputs":[],"source":[]}],"metadata":{"colab":{"gpuType":"T4","provenance":[{"file_id":"1Tt-Su-RVMyemiucC4GduyLxU5F-wj1up","timestamp":1701668064998},{"file_id":"18s8dhzZiBVwNJb0BcSvcl5gusHwo9eKl","timestamp":1692937040039},{"file_id":"1fV5Fe4INtqxcAY2TC3rOY_D6qIK6Aunv","timestamp":1689491508741},{"file_id":"1iM01swGT_NHCAqdUOnSnELxwk1ZYwuUr","timestamp":1689461508163}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
